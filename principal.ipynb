{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Ecopetrol       Nutresa  Bancolombia           ISA          Sura  \\\n",
      "Date                                                                           \n",
      "2023-11-24  10.485044  44920.730469    25.418125  14234.751953  30535.675781   \n",
      "2023-11-27  10.493268  44607.761719    26.007103  14122.666992  30012.207031   \n",
      "2023-11-28  10.583726  45104.832031    25.915073  14197.389648  29081.595703   \n",
      "2023-11-29  10.452149  45104.832031    25.703409  14160.028320  29081.595703   \n",
      "2023-11-30  10.369914  46006.925781    25.390514  14160.028320  29081.595703   \n",
      "\n",
      "               Promigas  Cementos Argos       Terpel          GEB        Exito  \n",
      "Date                                                                            \n",
      "2023-11-24  3965.564697        6.028093  6312.071289  1635.555054  3500.083252  \n",
      "2023-11-27  3941.560059        6.028093  6312.071289  1604.612183  3500.083252  \n",
      "2023-11-28  3941.560059        6.028093  6438.312500  1595.771240  3500.083252  \n",
      "2023-11-29  3955.962891        6.028093  6438.312500  1648.816284  3500.083252  \n",
      "2023-11-30  3955.962891        6.028093  6438.312500  1679.759155  3500.083252  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf  #  pip install yfinance\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de Ecopetrol desde Yahoo Finance\n",
    "ecopetrol = yf.download('EC', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de Nutresa desde Yahoo Finance\n",
    "nutresa = yf.download('NUTRESA.CL', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de Bancolombia desde Yahoo Finance\n",
    "bancolombia = yf.download('CIB', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de ISA desde Yahoo Finance\n",
    "isa = yf.download('ISA.CL', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de Sura desde Yahoo Finance\n",
    "sura = yf.download('GRUPOSURA.CL', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de Promigas desde Yahoo Finance\n",
    "promigas = yf.download('PROMIGAS.CL', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de Cementos Argos desde Yahoo Finance\n",
    "cementosargos = yf.download('CMTOY', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de Terpel desde Yahoo Finance\n",
    "terpel = yf.download('TERPEL.CL', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de GEB desde Yahoo Finance\n",
    "geb = yf.download('GEB.CL', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "# Descargar datos de cotizaciones de la acción de Éxito desde Yahoo Finance\n",
    "exito = yf.download('EXITO.CL', start='2013-01-01', end='2023-12-01')['Adj Close']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Crear un DataFrame combinando los datos\n",
    "data = pd.DataFrame({'Ecopetrol': ecopetrol,\n",
    "                    'Nutresa': nutresa,\n",
    "                    'Bancolombia': bancolombia,\n",
    "                    'ISA': isa,\n",
    "                    'Sura': sura,\n",
    "                    'Promigas': promigas,\n",
    "                    'Cementos Argos': cementosargos,\n",
    "                    'Terpel': terpel,\n",
    "                    'GEB': geb,\n",
    "                    'Exito': exito})\n",
    "\n",
    "# Verificar los primeros registros del DataFrame\n",
    "print(data.tail())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Ecopetrol       Nutresa  Bancolombia           ISA          Sura  \\\n",
      "count  2748.000000   2841.000000  2748.000000   2839.000000   2844.000000   \n",
      "mean      9.195153  23471.164033    27.993728  11633.759272  29533.429019   \n",
      "std       4.529940   9172.725481     5.977197   5074.288873   5608.309886   \n",
      "min       2.588103  14159.203125    12.061014   4056.786865  13120.189453   \n",
      "25%       6.165998  18858.169922    23.389375   6680.804199  27987.765137   \n",
      "50%       8.154275  20030.667969    26.991302  10641.953125  30440.925781   \n",
      "75%      10.652359  21433.298828    32.958539  15942.009277  32764.759766   \n",
      "max      24.876390  57300.230469    41.358707  24233.003906  53680.039062   \n",
      "\n",
      "           Promigas  Cementos Argos       Terpel          GEB        Exito  \n",
      "count   2843.000000     2748.000000  2417.000000  2839.000000  2842.000000  \n",
      "mean    4393.758277        9.999659  6419.339717  1167.858269  4336.393527  \n",
      "std     1693.351230        4.722510  1114.082528   351.775345  1284.753919  \n",
      "min     1614.296631        1.432291  4108.125000   582.130066  2296.916992  \n",
      "25%     3084.851318        6.013138  5583.558594   854.619995  3500.083252  \n",
      "50%     4032.777832        9.542668  6321.088379  1120.193115  3798.240601  \n",
      "75%     5346.500488       13.833371  7045.681641  1436.223511  4891.165283  \n",
      "max    12463.502930       22.764027  9494.981445  1998.389404  7824.023926  \n"
     ]
    }
   ],
   "source": [
    "# Realizo un análisis estadístico del DataFrame\n",
    "\n",
    "data_summary = data.describe()\n",
    "print(data_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudio de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de valores nulos por columna:\n",
      "Ecopetrol         100\n",
      "Nutresa             7\n",
      "Bancolombia       100\n",
      "ISA                 9\n",
      "Sura                4\n",
      "Promigas            5\n",
      "Cementos Argos    100\n",
      "Terpel            431\n",
      "GEB                 9\n",
      "Exito               6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculo la cantidad de valores nulos por columna\n",
    "null_values = data.isnull().sum()\n",
    "\n",
    "# Muestro los resultados\n",
    "print(\"Cantidad de valores nulos por columna:\")\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecopetrol         False\n",
      "Nutresa           False\n",
      "Bancolombia       False\n",
      "ISA               False\n",
      "Sura              False\n",
      "Promigas          False\n",
      "Cementos Argos    False\n",
      "Terpel            False\n",
      "GEB               False\n",
      "Exito             False\n",
      "dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
      "C:\\Users\\Andres\\AppData\\Local\\Temp\\ipykernel_7912\\223474087.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculo la interpolación lineal para reemplazar los valores nulos con los valores anterior y siguiente\n",
    "data_filled = data.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "# Identifico las posiciones de los valores nulos\n",
    "null_positions = data.isnull()\n",
    "\n",
    "# Itero sobre cada columna, excluyendo las columnas no numéricas\n",
    "for column in data.columns:\n",
    "    if data[column].dtype != 'object':  # Verifica si la columna es numérica\n",
    "        # Reemplazo los valores nulos con el promedio de los valores anterior y siguiente al nulo\n",
    "        data_filled[column][null_positions[column]] = data_filled[column].fillna(method='ffill').rolling(window=11, min_periods=1, center=True).mean()[null_positions[column]]\n",
    "\n",
    "# Verifico si todavía existen valores nulos después del proceso de interpolación\n",
    "print(pd.isnull(data_filled).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay valores nulos en data_filled.\n"
     ]
    }
   ],
   "source": [
    "# Verifico si hay valores nulos en data_filled\n",
    "if data_filled.isnull().any().any():\n",
    "    print(\"Todavía hay valores nulos en data_filled.\")\n",
    "else:\n",
    "    print(\"No hay valores nulos en data_filled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Ecopetrol   Nutresa  Bancolombia       ISA      Sura  Promigas  \\\n",
      "Date                                                                         \n",
      "2013-01-01   0.967840  0.095335     0.962422  0.137515  0.427866  0.840817   \n",
      "2013-01-02   0.970435  0.094668     0.944935  0.137515  0.414026  0.840817   \n",
      "2013-01-03   0.971835  0.090336     0.967161  0.137515  0.417585  0.840817   \n",
      "2013-01-04   0.971660  0.095001     0.974570  0.139984  0.417585  0.840817   \n",
      "2013-01-07   0.966936  0.095001     0.980978  0.139984  0.417585  0.840817   \n",
      "\n",
      "            Cementos Argos    Terpel       GEB     Exito  \n",
      "Date                                                      \n",
      "2013-01-01             1.0  0.824485  0.000000  0.958505  \n",
      "2013-01-02             1.0  0.824485  0.016182  0.958505  \n",
      "2013-01-03             1.0  0.824485  0.033983  0.962728  \n",
      "2013-01-04             1.0  0.824485  0.035601  1.000000  \n",
      "2013-01-07             1.0  0.824485  0.035601  1.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Creo un objeto MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data = data_filled\n",
    "\n",
    "# Excluyo la columna \"city\" de la normalización\n",
    "columns_to_normalize = data.columns.difference([\"Date\"])\n",
    "\n",
    "# Normalizo los datos\n",
    "data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])\n",
    "\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
